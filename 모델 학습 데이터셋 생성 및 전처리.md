

## 모델 학습 데이터셋 생성 및 전처리

**1. 데이터 수집:**
- `songys/Chatbot_data` GitHub 저장소에서 `ChatbotData.csv` 파일을 다운로드하여 사용합니다. 이 데이터셋은 챗봇 트레이닝용 문답 페어 11,876개로 구성되어 있으며, 일상다반사, 이별(부정), 사랑(긍정)으로 레이블링되어 있습니다.

**2. 데이터 전처리:**
- **불필요한 컬럼 제거:** `Q` (질문), `A` (답변), `label` (감성 레이블) 컬럼만 유지하고, 다른 불필요한 컬럼은 제거합니다.
- **결측치 처리:** 데이터셋 내에 결측치가 있는지 확인하고, 있다면 해당 행을 제거하거나 적절한 값으로 대체합니다.
- **텍스트 정제:**
    - 특수문자, 이모티콘, 불필요한 공백 등을 제거합니다.
    - 한글 외의 문자(영어, 숫자 등)는 필요에 따라 유지하거나 제거합니다.
    - 오탈자 및 비속어 등을 정제합니다.
- **토큰화 (Tokenization):**
    - 한국어 자연어 처리에 적합한 형태소 분석기 (예: KoNLPy의 Mecab, Okt 등)를 사용하여 문장을 형태소 단위로 분리합니다.
    - 불용어 (Stopwords)를 제거하여 모델 학습에 불필요한 단어들을 필터링합니다.
- **데이터 분할:**
    - 학습 (Train), 검증 (Validation), 테스트 (Test) 세트로 데이터를 분할합니다. 일반적으로 8:1:1 또는 7:1.5:1.5 비율로 분할합니다.
    - `label` 컬럼을 기준으로 계층적 샘플링(Stratified Sampling)을 적용하여 각 세트에 레이블 분포가 고르게 포함되도록 합니다.

**3. 데이터 로더 구축:**
- PyTorch의 `Dataset` 및 `DataLoader` 클래스를 활용하여 전처리된 데이터를 효율적으로 모델에 공급할 수 있도록 데이터 로더를 구축합니다.
- 각 샘플은 `(질문 텍스트, 답변 텍스트, 레이블)` 형태로 구성됩니다.
- 배치(Batch) 처리를 위해 `collate_fn`을 구현하여 가변 길이 시퀀스에 대한 패딩(Padding)을 처리합니다.

**4. 데이터셋 저장:**
- 전처리된 데이터셋은 `.csv` 또는 `.json` 파일 형태로 저장하여 재사용성을 높입니다.
- 토큰화된 데이터는 모델 학습 시 바로 사용할 수 있도록 넘파이 배열(`.npy`) 또는 PyTorch 텐서(`.pt`) 형태로 저장할 수 있습니다.

